{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Concatenation\n",
    "Not to be confused with merge, concatenating dataframes means to reuse the same columns and extend the size of the dataframe, dependent on your axis. It's useful if your data is split into partitions, but need to combine them into a monolithic dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Concatenate uber1, uber2, and uber3: row_concat\n",
    "# row_concat = pd.concat([uber1, uber2, uber3])\n",
    "\n",
    "# # Print the shape of row_concat\n",
    "# print(row_concat.shape)\n",
    "\n",
    "# # Print the head of row_concat\n",
    "# print(row_concat.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, axis=0 meaning that the dataframes are concatenated row-wise. Axis=1 means that the dataframes are concatenated column-wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Concatenate ebola_melt and status_country column-wise: ebola_tidy\n",
    "# ebola_tidy = pd.concat([ebola_melt, status_country], axis=1)\n",
    "\n",
    "# # Print the shape of ebola_tidy\n",
    "# print(ebola_tidy.shape)\n",
    "\n",
    "# # Print the head of ebola_tidy\n",
    "# print(ebola_tidy.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding files that match a pattern\n",
    "You're now going to practice using the glob module to find all csv files in the workspace. In the next exercise, you'll programmatically load them into DataFrames.\n",
    "\n",
    "As Dan showed you in the video, the glob module has a function called glob that takes a pattern and returns a list of the files in the working directory that match that pattern.\n",
    "\n",
    "For example, if you know the pattern is part_ single digit number .csv, you can write the pattern as 'part_?.csv' (which would match part_1.csv, part_2.csv, part_3.csv, etc.)\n",
    "\n",
    "Similarly, you can find all .csv files with '*.csv', or all parts with 'part_*'. The ? wildcard represents any 1 character, and the * wildcard represents any number of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import necessary modules\n",
    "# import glob\n",
    "# import pandas as pd\n",
    "\n",
    "# # Write the pattern: pattern\n",
    "# pattern = '*.csv'\n",
    "\n",
    "# # Save all file matches: csv_files\n",
    "# csv_files = glob.glob(pattern)\n",
    "\n",
    "# # Print the file names\n",
    "# print(csv_files)\n",
    "\n",
    "# # Load the second file into a DataFrame: csv2\n",
    "# csv2 = pd.read_csv(csv_files[1])\n",
    "\n",
    "# # Print the head of csv2\n",
    "# print(csv2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating and concatenating all matches\n",
    "Now that you have a list of filenames to load, you can load all the files into a list of DataFrames that can then be concatenated.\n",
    "\n",
    "You'll start with an empty list called frames. Your job is to use a for loop to:\n",
    "\n",
    "iterate through each of the filenames\n",
    "read each filename into a DataFrame, and then\n",
    "append it to the frames list.\n",
    "You can then concatenate this list of DataFrames using pd.concat(). Go for it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create an empty list: frames\n",
    "# frames = []\n",
    "\n",
    "# #  Iterate over csv_files\n",
    "# for csv in csv_files:\n",
    "\n",
    "#     #  Read csv into a DataFrame: df\n",
    "#     df = pd.read_csv(csv)\n",
    "    \n",
    "#     # Append df to frames\n",
    "#     frames.append(df)\n",
    "\n",
    "# # Concatenate frames into a single DataFrame: uber\n",
    "# uber = pd.concat(frames)\n",
    "\n",
    "# # Print the shape of uber\n",
    "# print(uber.shape)\n",
    "\n",
    "# # Print the head of uber\n",
    "# print(uber.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Merge\n",
    "\n",
    "Merging data allows you to combine disparate datasets into a single dataset to do more complex analysis.\n",
    "\n",
    "Two DataFrames have been pre-loaded: site and visited. Explore them in the IPython Shell and take note of their structure and column names. Your task is to perform a 1-to-1 merge of these two DataFrames using the 'name' column of site and the 'site' column of visited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Merge the DataFrames: o2o\n",
    "# o2o = pd.merge(left=site, right=visited, left_on='name', right_on='site')\n",
    "\n",
    "# # Print o2o\n",
    "# print(o2o.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Merge the DataFrames: m2o\n",
    "# m2o = pd.merge(left=site, right=visited, left_on='name', right_on='site')\n",
    "\n",
    "# # Print m2o\n",
    "# print(m2o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Many-to-many data merge\n",
    "The final merging scenario occurs when both DataFrames do not have unique keys for a merge. What happens here is that for each duplicated key, every pairwise combination will be created.\n",
    "\n",
    "Two example DataFrames that share common key values have been pre-loaded: df1 and df2. Another DataFrame df3, which is the result of df1 merged with df2, has been pre-loaded. All three DataFrames have been printed - look at the output and notice how pairwise combinations have been created. This example is to help you develop your intuition for many-to-many merges.\n",
    "\n",
    "Here, you'll work with the site and visited DataFrames from before, and a new survey DataFrame. Your task is to merge site and visited as you did in the earlier exercises. You will then merge this merged DataFrame with survey.\n",
    "\n",
    "Begin by exploring the site, visited, and survey DataFrames in the IPython Shell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Merge site and visited: m2m\n",
    "# m2m = pd.merge(left=site, right=visited, left_on='name', right_on='site')\n",
    "\n",
    "# # Merge m2m and survey: m2m\n",
    "# m2m = pd.merge(left=m2m, right=survey, left_on='ident', right_on='taken')\n",
    "\n",
    "# # Print the first 20 lines of m2m\n",
    "# print(m2m.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
